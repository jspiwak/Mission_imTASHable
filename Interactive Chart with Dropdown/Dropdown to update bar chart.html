<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>d3 Updating Bar Chart With Dropdown</title>
        <script src="http://d3js.org/d3.v3.min.js" charset="utf-8"></script>
        <style>
        body {
            font: 10px sans-serif;
        }
        select {
            display: block;
        }
        .bar {
            fill: #86C232;
            opacity: 0.8;
        }

        .axis path,
        .axis line {
            fill: none;
            stroke: #000;
            shape-rendering: crispEdges;
        }

        p {
            font-size: 15px;
        }

        h1 {
            font-size: 40px;
        }
        </style>
    </head>
    <body>
        <div>
            <h1>Audio Analysis of Top Tracks</h1>
            <br>
            <hr>
            <h2><strong>Audio Description:</strong></h2>
            <p><strong>Acousticness</strong> is a measure of how many prominent “acoustic” sounds (for example acoustic guitar and tambourine) a given track has, versus how many electronic sounds (synthesizer, drum machine) it has, as determined by computers listening to music.</p>
            <br>
            <p><strong>Danceability</strong> describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.</p>
            <br>
            <p>Typically, <strong>Energetic</strong> tracks feel fast, loud, and noisy. As a couple examples, death metal has high energy, while a Bach prelude scores low on the energy scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.</p>
            <br>
            <p><strong>Instrumentalness</strong> predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The higher the instrumentalness value for a track, the greater likelihood that it contains no vocal content.</p>
            <br>
            <p><strong>Valence</strong> measures the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).</p>
            <br>
            <p><strong>Liveness</strong> detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.</p>
        



        </div>
        <hr>
        <br>
        <div id='vis-container'></div>
        <script type="text/javascript">
            // Load and munge data, then make the visualization.
            var fileName = "Audio Stats.csv";
            var audioFields = ["Danceability", "Valence", "Energy", "Acousticness", "Instrumentalness",
                                   "Liveness"];

            d3.csv(fileName, function(error, data) {
                var trackMap = {};
                data.forEach(function(d) {
                    var track = d.Track_name;
                    trackMap[track] = [];

                    // { cerealName: [ bar1Val, bar2Val, ... ] }
                    audioFields.forEach(function(field) {
                        trackMap[track].push( +d[field] );
                    });
                });
                makeVis(trackMap);
            });

            var makeVis = function(trackMap) {
                // Define dimensions of vis
                var margin = { top: 30, right: 50, bottom: 30, left: 50 },
                    width  = 650 - margin.left - margin.right,
                    height = 350 - margin.top  - margin.bottom;

                // Make x scale
                var xScale = d3.scale.ordinal()
                    .domain(audioFields)
                    .rangeRoundBands([0, width], 0.1);

                // Make y scale, the domain will be defined on bar update
                var yScale = d3.scale.linear()
                    .range([height, 0]);

                // Create canvas
                var canvas = d3.select("#vis-container")
                  .append("svg")
                    .attr("width",  width  + margin.left + margin.right)
                    .attr("height", height + margin.top  + margin.bottom)
                  .append("g")
                    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

                // Make x-axis and add to canvas
                var xAxis = d3.svg.axis()
                    .scale(xScale)
                    .orient("bottom");

                canvas.append("g")
                    .attr("class", "x axis")
                    .attr("transform", "translate(0," + height + ")")
                    .call(xAxis);

                // Make y-axis and add to canvas
                var yAxis = d3.svg.axis()
                    .scale(yScale)
                    .orient("left");

                var yAxisHandleForUpdate = canvas.append("g")
                    .attr("class", "y axis")
                    .call(yAxis);

                yAxisHandleForUpdate.append("text")
                    .attr("transform", "rotate(-90)")
                    .attr("y", 6)
                    .attr("dy", ".71em")
                    .style("text-anchor", "end")
                    .text("Value");

                var updateBars = function(data) {
                    // First update the y-axis domain to match data
                    yScale.domain( d3.extent(data) );
                    yAxisHandleForUpdate.call(yAxis);

                    var bars = canvas.selectAll(".bar").data(data);

                    // Add bars for new data
                    bars.enter()
                      .append("rect")
                        .attr("class", "bar")
                        .attr("x", function(d,i) { return xScale( audioFields[i] ); })
                        .attr("width", xScale.rangeBand())
                        .attr("y", function(d,i) { return yScale(d); })
                        .attr("height", function(d,i) { return height - yScale(d); });

                    // Update old ones, already have x / width from before
                    bars
                        .transition().duration(250)
                        .attr("y", function(d,i) { return yScale(d); })
                        .attr("height", function(d,i) { return height - yScale(d); });

                    // Remove old ones
                    bars.exit().remove();
                };

                // Handler for dropdown value change
                var dropdownChange = function() {
                    var newTrack = d3.select(this).property('value'),
                        newData   = trackMap[newTrack];

                    updateBars(newData);
                };

                // Get names of cereals, for dropdown
                var tracks = Object.keys(trackMap).sort();

                var dropdown = d3.select("#vis-container")
                    .insert("select", "svg")
                    .on("change", dropdownChange);

                dropdown.selectAll("option")
                    .data(tracks)
                  .enter().append("option")
                    .attr("value", function (d) { return d; })
                    .text(function (d) {
                        return d[0].toUpperCase() + d.slice(1,d.length); // capitalize 1st letter
                    });

                var initialData = trackMap[ tracks[1] ];
                updateBars(initialData);
            };
        </script>
    </body>
</html>